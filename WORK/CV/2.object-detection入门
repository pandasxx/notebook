性能衡量指标
	
	https://blog.csdn.net/katherine_hsr/article/details/79266880


物体检测算法1：从传统到深度

	传统方法的演进

		1 检测窗口选择
			搜索框遍历+图像金字塔
			先验检测
			selective search，edge box等proposal提取方法

		2 特征的设计
			Haar，LBP，HOG等不同方法适用于不同特征

		3 分类器的设计
			adaboost
			SVM
			decision tree

	从传统方法到深度学习

		穷举法 RCNN：选定多个候选框 + 对候选框分类
			
		减少候选框数量：SS算法减少候选框数量

		减少重复的特征提取，分类计算

		
		
		SPP对整图提取固定大小特征

		RPN计算候选网络




	公开数据集
		PASCAL VOC & COCO






参考
https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650725146&idx=3&sn=453e29cb6179e8e06df2133269c20812&chksm=871b1f64b06c967276274cee90f5a036c09b08cec9e52111af6744c7f0c19d5a8c7e0eb06e0b&scene=21#wechat_redirect






物体检测算法2：R-CNN
	
	启发思想

		检测窗口选择，暴力枚举
			从直接输出 xywh回归，到枚举窗口，对窗口进行打分和修正

		窗口截取之后的分类，普通图像分类问题

		窗口截取之后的坐标回归（修正），回归问题和得分评价
			输入图片，输出方框坐标（x、y、w、h），使用IOU评价标准

			预测出 x y w h四个值和taget求欧式距离作为损失loss

			对窗口进行打分

	R-CNN

		一个分类模型（这里是alexnet），去掉最后的全连接层，改掉分类个数（适配现有分类任务）

		使用SS算法得到候选框，修正候选框尺寸输入到分类模型，将输出的特征保存

		训练一个分类器来判断输出特征的类别

		训练一个回归器来判断输出特征的候选框位置是否准确

物体检测算法3：R-CNN的改进
	
	重要手段

		SPP Net
			1 在卷积后，fc前。卷积输入任意尺寸的图像，经过spp net 会转化成相同尺寸的特征给fc层。
			2 只需提取一次特征，候选框可以在提取的特征上提取patch，再经过spp net传递到后面的层

		RPN （候选区域网络）
			K个锚点框
			4K个坐标和2K个分数

	Fast R-CNN

		在卷积层之后，全连接层之前，加入了ROI Pooling（可以视为单层SPP Net）
		使得只需对输入图片提取一次特征，在卷积层提取特征之后，在根据候选框在特征图上截取
		截取后的proposal经过ROI Pooling会变成大小一致的特征给后续的FC层

		除了外部候选区域算法之外，已经是端到端了（分类器和回归器已用神经网络实现）

	Faster R-CNN 
		使用RPN网络根据图像的特征图来进行候选区域选择，而非外部候选区域选择算法

		彻底的端到端模型

	R-FCN
		减少每个ROI的计算量

		针对 RCNN对每个ROI都经过FC，会重复大量计算
		使用全卷积网络，且尽量把后面的重复计算挪到前面的共享计算当中

参考
https://www.cnblogs.com/skyfsm/p/6806246.html



物体检测算法4：单次检测算法
	
	YOLO
		同时预测分界框和类别（不同于两阶段算法的分别预测边界框和类别）
		即 8 × 8 × D（3× 3× D × 5） -> 8 × 8 × 5 改为 8 × 8 × D（3× 3× D × 25） -> 8 × 8 × 25
		前者只预测坐标（4）和置信度（1），后者需要预测坐标（4）置信度（1）类别（20）

		1 使用darknet作为特征提取器

		2 全卷积网络

		3 统一预测类别和分界

		4 生成的锚点框是提前算好的，可配置












